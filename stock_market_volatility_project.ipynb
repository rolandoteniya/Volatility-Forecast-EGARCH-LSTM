{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbV/QUIfW9Ok8neg7ZF5JY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rolandoteniya/Volatility-Forecast-EGARCH-LSTM/blob/main/stock_market_volatility_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "5mHkOU4-rBws",
        "outputId": "ab51a02f-1488-43d7-a3ae-5bb7cd8b8a64"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (ipython-input-1-3533713889.py, line 130)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1-3533713889.py\"\u001b[0;36m, line \u001b[0;32m130\u001b[0m\n\u001b[0;31m    actual_volatility = val_data['sp500 log rtns']**2.values\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ],
      "source": [
        "#DOWNLOAD LIBRARY\n",
        "!pip install -q arch\n",
        "!pip install -q shap\n",
        "\n",
        "#SET UP ENVIRONMENT\n",
        "#libraries to to start with\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from arch import arch_model\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import date\n",
        "import math\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "#ACQUIRE CORE & EXOGENOUS DATA\n",
        "#downloading s&p500 data from 1 jan 2000 to present day\n",
        "sp500 = yf.download(tickers=\"^GSPC\", start=\"1999-12-02\", end=\"2025-07-01\")\n",
        "\n",
        "#downloadiing vix data from 1 jan 2000 to present day\n",
        "vix = yf.download(tickers=\"^VIX\", start=\"1999-12-02\", end=\"2025-07-01\")\n",
        "\n",
        "#PREPROCESS AND ALIGN DATA\n",
        "#choose only close price for sp500\n",
        "close_sp500 = sp500['Close']\n",
        "\n",
        "#choose only close price for vix\n",
        "close_vix = vix['Close']\n",
        "\n",
        "#calculate log retuns using a vecotirse operation\n",
        "sp500_logrtn = np.log(close_sp500 / close_sp500.shift(1))\n",
        "\n",
        "#first value will be not a number so we remove it\n",
        "sp500_logrtn = sp500_logrtn.dropna()\n",
        "\n",
        "#augmented dickey-fuller (adf) test\n",
        "\"\"\"1st test statistic\n",
        "2nd p value\n",
        "4th number of datapoints\n",
        "\"\"\"\n",
        "adfuller(sp500_logrtn)\n",
        "#print(adfuller(sp500_logrtn))\n",
        "\n",
        "#align the snp500 log rtns with the vix closing price\n",
        "#inner join ensures that only dates present in both datasets are kept\n",
        "aligned_data = pd.concat([sp500_logrtn, close_vix], axis=1, join='inner')\n",
        "\n",
        "#rename columns for clarity\n",
        "aligned_data.columns = ['sp500_log_retuns','close_vix']\n",
        "\n",
        "#display first few rows of aligned data\n",
        "#print(aligned_data.head())\n",
        "\n",
        "#GENERATE TARGET VARIABLE\n",
        "#calculate 21 day future realised volatility\n",
        "future_volatility = sp500_logrtn.shift(-21).rolling(window=21).std()*(252**.5)\n",
        "\n",
        "#first few values will be not a number so we remove it\n",
        "future_volatility = future_volatility.dropna()\n",
        "#align snp500 log rtns, vix and future realised volatility togehter\n",
        "aligned_data = pd.concat([sp500_logrtn, close_vix, future_volatility], axis=1, join='inner')\n",
        "\n",
        "#rename columns for clarity\n",
        "aligned_data.columns = ['sp500 log rtns', 'close vix', 'future volatility']\n",
        "\n",
        "#display first few rows of algined data\n",
        "#print(aligned_data.head())\n",
        "\n",
        "#SPLIT DATA\n",
        "# train_data = []\n",
        "# val_data = []\n",
        "# test_data = []\n",
        "# for i in range(0,int(len(aligned_data) * 0.7)):\n",
        "#   train_data.append(aligned_data.iloc[i])\n",
        "# # print(len(train_data))\n",
        "\n",
        "# for i in range(int(len(aligned_data) * 0.7), int(len(aligned_data) * 0.85)):\n",
        "#   val_data.append(aligned_data.iloc[i])\n",
        "# # print(len(val_data))\n",
        "\n",
        "# for i in range(int(len(aligned_data) * 0.85), len(aligned_data)):\n",
        "#   test_data.append(aligned_data.iloc[i])\n",
        "# # print(len(test_data))\n",
        "\n",
        "# print(len(aligned_data))\n",
        "# print(len(train_data)+ len(val_data) + len(test_data))\n",
        "\n",
        "#first calculate the split points\n",
        "split1 = int(len(aligned_data) * 0.7)\n",
        "split2 = int(len(aligned_data) * 0.85)\n",
        "\n",
        "#perform slicing in one step for each set\n",
        "train_data = aligned_data.iloc[:split1]\n",
        "val_data = aligned_data.iloc[split1:split2]\n",
        "test_data = aligned_data.iloc[split2:]\n",
        "\n",
        "# #verify splits\n",
        "# print(len(train_data)+len(val_data)+len(test_data))\n",
        "# print(len(aligned_data))\n",
        "\n",
        "#TEST DIFFERENT GARCH PARAMETERS\n",
        "# select log returns from training data\n",
        "returns_train = train_data['sp500 log rtns']\n",
        "\n",
        "#specify the GARCH(1,1) model\n",
        "#we use p=1 and q=1 for the GARCH and ARCH terms.\n",
        "garch_model = arch_model(returns_train, p=1, q=1)\n",
        "\n",
        "#fit the model to the data\n",
        "garch_results = garch_model.fit(disp=\"off\")\n",
        "\n",
        "#print the summary of the results\n",
        "#print(garch_results.summary())\n",
        "\n",
        "#FORECAST VOLATILITY USING GARCH(1,1) model that was trainded only on the training data.\n",
        "garch_forecast = garch_results.forecast(horizon=len(val_data))\n",
        "\n",
        "#get the forecasted variance. reset the index to remove the date.\n",
        "#.values converts it to a simple numpy array\n",
        "predicted_variance = garch_forecast.variance.iloc[0].values\n",
        "\n",
        "#get the actual volatility from the validation set.\n",
        "#resetting the index here isn't strictly necessary but is good practice\n",
        "actual_volatility = val_data['future volatility'].values\n",
        "\n",
        "#calculate the RMSE\n",
        "#no need to align or fill, as both are now simple arrays of the same length\n",
        "rmse_garch = np.sqrt(mean_squared_error(actual_volatility, np.sqrt(predicted_variance)))\n",
        "\n",
        "print(f'GARCH(1,1) RMSE: {rmse_garch}')\n",
        "\n",
        "\n",
        "egarch_model = arch_model(returns_train, vol=\"EGARCH\",p=1, o=1, q=1)\n",
        "\n",
        "#fit the model to the data\n",
        "egarch_results = egarch_model.fit(disp='off')\n",
        "\n",
        "#forecast volatility using egarch(1,1)\n",
        "egarch_forecast = egarch_results.forecast(horizon=len(val_data), method=\"simulation\")\n",
        "predicted_variance = egarch_forecast.variance.iloc[0].values\n",
        "actual_volatility = val_data['future volatility'].values\n",
        "rmse_egarch = np.sqrt(mean_squared_error(actual_volatility, np.sqrt(predicted_variance)))\n",
        "\n",
        "print(f'EGARCH(1,1) RMSE: {rmse_egarch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fAkI_ZyOfZxP"
      }
    }
  ]
}